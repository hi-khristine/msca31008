{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain logistic regression isn't looking promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"./out/d_fight_level_dataset_1line.csv\", index_col = 0)\n",
    "\n",
    "# Change winner to binary 1/0:\n",
    "data.Winner = data.Winner.apply(lambda x: np.where(x == -1, 0, 1))\n",
    "\n",
    "# Initial features and target\n",
    "features = pd.Series(data.columns, index = data.columns)\n",
    "target = \"Winner\"\n",
    "\n",
    "# Remove referree, date, location, winner, title_bout, weight_class, no_of_rounds\n",
    "features.drop(index = [\"Referee\", \"date\", \"location\", \"Winner\", \"title_bout\",\n",
    "                       \"weight_class\", \"no_of_rounds\"], inplace = True)\n",
    "\n",
    "# Diff_draw is mostly NA/0\n",
    "features.drop(index = \"Diff_draw\", inplace = True)\n",
    "\n",
    "# Lots of win columns\n",
    "features.drop(index = [\"Diff_win_by_Decision_Majority\",\n",
    "                       \"Diff_win_by_Decision_Split\",\n",
    "                       \"Diff_win_by_Decision_Unanimous\",\n",
    "                       \"Diff_win_by_KO/TKO\",\n",
    "                       \"Diff_win_by_Submission\",\n",
    "                       \"Diff_win_by_TKO_Doctor_Stoppage\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just throw everything in, getting lots of bad p-values (and a pretty bad r-squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652126\n",
      "         Iterations 5\n",
      "                                Results: Logit\n",
      "===============================================================================\n",
      "Model:                   Logit                 Pseudo R-squared:      0.009    \n",
      "Dependent Variable:      Winner                AIC:                   3090.0410\n",
      "Date:                    2019-11-17 15:41      BIC:                   3296.9234\n",
      "No. Observations:        2314                  Log-Likelihood:        -1509.0  \n",
      "Df Model:                35                    LL-Null:               -1522.0  \n",
      "Df Residuals:            2278                  LLR p-value:           0.86368  \n",
      "Converged:               1.0000                Scale:                 1.0000   \n",
      "No. Iterations:          5.0000                                                \n",
      "-------------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Diff_age                         0.0171   0.0092  1.8713 0.0613 -0.0008  0.0351\n",
      "Diff_Height_cms                 -0.0217   0.0095 -2.2860 0.0223 -0.0403 -0.0031\n",
      "Diff_Reach_cms                   0.0253   0.0074  3.4163 0.0006  0.0108  0.0398\n",
      "Diff_Weight_lbs                  0.0116   0.0045  2.5818 0.0098  0.0028  0.0204\n",
      "Diff_avg_KD                      0.0827   0.1252  0.6607 0.5088 -0.1627  0.3282\n",
      "Diff_avg_PASS                    0.1385   0.0368  3.7687 0.0002  0.0665  0.2106\n",
      "Diff_avg_REV                    -0.0367   0.1518 -0.2418 0.8090 -0.3341  0.2607\n",
      "Diff_avg_BODY_pct                0.1293   0.2468  0.5238 0.6004 -0.3544  0.6129\n",
      "Diff_avg_CLINCH_pct             -0.2336   0.2218 -1.0533 0.2922 -0.6683  0.2011\n",
      "Diff_avg_DISTANCE_pct            1.1007   0.7130  1.5438 0.1226 -0.2967  2.4981\n",
      "Diff_avg_GROUND_pct              0.0163   0.1823  0.0893 0.9288 -0.3410  0.3735\n",
      "Diff_avg_HEAD_pct                0.5023   0.8397  0.5982 0.5497 -1.1435  2.1480\n",
      "Diff_avg_LEG_pct                 0.0590   0.1820  0.3244 0.7456 -0.2976  0.4157\n",
      "Diff_avg_SIG_STR_pct             0.3129   1.3827  0.2263 0.8210 -2.3972  3.0229\n",
      "Diff_avg_TD_pct                 -0.0180   0.1406 -0.1283 0.8979 -0.2936  0.2575\n",
      "Diff_avg_TOTAL_STR_pct          -1.7661   0.7492 -2.3575 0.0184 -3.2344 -0.2978\n",
      "Diff_current_lose_streak        -0.0002   0.0553 -0.0045 0.9964 -0.1085  0.1080\n",
      "Diff_current_win_streak          0.0438   0.0271  1.6199 0.1052 -0.0092  0.0969\n",
      "Diff_longest_win_streak          0.0126   0.0345  0.3662 0.7142 -0.0550  0.0803\n",
      "Diff_losses                     -0.0478   0.0433 -1.1041 0.2695 -0.1327  0.0371\n",
      "Diff_total_rounds_fought        -0.0125   0.0130 -0.9674 0.3334 -0.0380  0.0129\n",
      "Diff_total_time_fought(seconds)  0.0007   0.0003  2.4642 0.0137  0.0001  0.0012\n",
      "Diff_total_title_bouts           0.0159   0.0239  0.6663 0.5052 -0.0309  0.0628\n",
      "Diff_wins                        0.0635   0.0362  1.7541 0.0794 -0.0074  0.1344\n",
      "Diff_avg_opp_KD                 -0.3909   0.1534 -2.5481 0.0108 -0.6917 -0.0902\n",
      "Diff_avg_opp_PASS               -0.0830   0.0367 -2.2642 0.0236 -0.1549 -0.0112\n",
      "Diff_avg_opp_REV                -0.0641   0.1481 -0.4327 0.6652 -0.3543  0.2262\n",
      "Diff_avg_opp_BODY_pct           -0.0495   0.0430 -1.1511 0.2497 -0.1339  0.0348\n",
      "Diff_avg_opp_CLINCH_pct          0.0734   0.0406  1.8054 0.0710 -0.0063  0.1530\n",
      "Diff_avg_opp_DISTANCE_pct        0.1399   0.2738  0.5111 0.6093 -0.3967  0.6766\n",
      "Diff_avg_opp_GROUND_pct          0.0142   0.0074  1.9288 0.0538 -0.0002  0.0287\n",
      "Diff_avg_opp_HEAD_pct            0.1123   0.2123  0.5289 0.5969 -0.3039  0.5285\n",
      "Diff_avg_opp_LEG_pct            -0.0078   0.0213 -0.3651 0.7150 -0.0496  0.0340\n",
      "Diff_avg_opp_SIG_STR_pct        -0.0948   0.3693 -0.2567 0.7974 -0.8187  0.6291\n",
      "Diff_avg_opp_TD_pct             -0.0285   0.0291 -0.9784 0.3279 -0.0856  0.0286\n",
      "Diff_avg_opp_TOTAL_STR_pct       0.3312   0.1670  1.9837 0.0473  0.0040  0.6584\n",
      "===============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive throw everything in\n",
    "logit_model = sm.Logit(data[target], data[features])\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean wins: 0.632238547968885 \n",
      "Mean predict: 0.5298946128329104\n",
      "\n",
      "Accuracy predicting all wins:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       851\n",
      "           1       0.63      1.00      0.77      1463\n",
      "\n",
      "    accuracy                           0.63      2314\n",
      "   macro avg       0.32      0.50      0.39      2314\n",
      "weighted avg       0.40      0.63      0.49      2314\n",
      "\n",
      "Accuracy with varying cutoffs:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions and check recall, precision, f1 score.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "pred = result.predict()\n",
    "print( \n",
    "    'Mean wins: %s \\nMean predict: %s\\n' % ( \n",
    "    data.Winner.mean(),\n",
    "    pred.mean()\n",
    "))\n",
    "\n",
    "# what is our base level if we predict the majority?\n",
    "print( 'Accuracy predicting all wins:\\n')\n",
    "print( classification_report( \n",
    "    data.Winner, \n",
    "    [ 1 for x in pred ]\n",
    "))\n",
    "\n",
    "# what is the outcome of different cutoffs?\n",
    "print( 'Accuracy with varying cutoffs:\\n' )\n",
    "for i in range(11): \n",
    "    \n",
    "    icutoff = i/10\n",
    "    \n",
    "    predwin = [ 1 if x > i/10 else 0 for x in pred ]\n",
    "    predloss = [ 0 if x > i/10 else 1 for x in pred ]\n",
    "    \n",
    "    fscorewin = f1_score( data.Winner, predwin )\n",
    "    fscoreloss = f1_score( ( data.Winner == 0 ) * 1, predloss )    \n",
    "    prec = precision_score( data.Winner, predwin )\n",
    "    recall = recall_score( data.Winner, predwin )\n",
    "    \n",
    "    print(\n",
    "        '%s: \\t f1-score: %s   \\t precision %s   \\t recall: %s' % ( \n",
    "            i/10, \n",
    "            round( (fscorewin + fscoreloss) / 2, 2 ),\n",
    "            round( prec, 2 ),\n",
    "            round( recall, 2 )\n",
    "    ))\n",
    "    \n",
    "print( '''\n",
    "Seems like a cutoff of around .5 gives us way above average wins \n",
    "while participating in a large number of fights.\n",
    "We are capturing 65% of the wins (recall) and winning 70% of the time.\n",
    "Strangely though, we could win 63% of the time and capture 100% of the wins by\n",
    "always betting to win.\n",
    "I guess we need to think about betting and what make the most sense.\n",
    "Here are the stats for a .5 cutoff:\n",
    "''')\n",
    "\n",
    "print( classification_report( \n",
    "    data.Winner, \n",
    "    [ 1 if x > 0.5 else 0 for x in pred ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove most of the insignificant features to see if something looks better. The only problem is that there isn't much predictive value regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_adj = features.drop(index = result.summary2().tables[1].index[result.summary2().tables[1][\"P>|z|\"] > .15])\n",
    "logit_model = sm.Logit(data[target], data[features_adj])\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the effects are different by weight class? These results show more promise in some cases (though probably not enough effectiveness for a betting strategy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.DataFrame(data.weight_class.value_counts())\n",
    "classes.drop(index = classes.index[np.where(classes.weight_class < 100)], inplace = True)\n",
    "\n",
    "for x in range(len(classes.index)):\n",
    "    df = data.loc[data.weight_class == classes.index[x]]\n",
    "    print(\"Class: \" + classes.index[x])\n",
    "    logit_model = sm.Logit(df[target], df[features_adj])\n",
    "    result = logit_model.fit()\n",
    "    print(result.summary2())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
